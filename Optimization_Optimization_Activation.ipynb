{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization of the Optimization algorithm and Activation\n",
    "Course: 8P361  &emsp;&emsp;  Group: 10\n",
    "\n",
    "Helgers, V.M.J. \t&emsp;&emsp; 1329332 <br>\n",
    "Jong, de R.L.P.D.\t&emsp;  1328328 <br>\n",
    "Korsten, T.\t\t    &emsp;&emsp;&emsp;&emsp; 1340522 <br>\n",
    "Moharir, S. \t\t&emsp;&emsp;&emsp;&emsp; 1296256 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important notes\n",
    "\n",
    "1. Note that all functions needed to execute this notebook can be found in the Optimization_Optimization_Activation.py file.\n",
    "\n",
    "2. If one wants to run this notebook it is important to add the right path to the image data within the function 'get_pcam_generators' which is called below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What the notebook does\n",
    "This notebook varies the Optimization algorithm and the activation of the model.\n",
    "For the activations, LeakyReLU, ReLU, and TanH are being used. \n",
    "For the optimization algorithm, SGD, Adam, and Nadam are being used.\n",
    "All possible combinations of these activations and optimizations algorithms are imported and subsequently trained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. First, import the relevant functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Optimization_Optimization_Activation.py import get_pcam_generators, get_model, train_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 LeakyReLU activation, SGD optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_genLS, val_genLS = get_pcam_generators('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/8p361-lecturer/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4500/4500 [==============================] - 138s 30ms/step - loss: 0.6636 - accuracy: 0.5623 - val_loss: 0.4542 - val_accuracy: 0.7949\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.45422, saving model to modelLS_weights.hdf5\n",
      "Epoch 2/3\n",
      "4500/4500 [==============================] - 131s 29ms/step - loss: 0.4471 - accuracy: 0.7946 - val_loss: 0.3902 - val_accuracy: 0.8269\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.45422 to 0.39023, saving model to modelLS_weights.hdf5\n",
      "Epoch 3/3\n",
      "4500/4500 [==============================] - 132s 29ms/step - loss: 0.3516 - accuracy: 0.8498 - val_loss: 0.3440 - val_accuracy: 0.8556\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.39023 to 0.34400, saving model to modelLS_weights.hdf5\n"
     ]
    }
   ],
   "source": [
    "##### Get the model\n",
    "modelLS = get_model('leakyrelu','SGD')\n",
    "\n",
    "# Train the model\n",
    "train_model(modelLS, train_genLS, val_genLS, 'modelLS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 ReLU activation, SGD optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_genRS, val_genRS = get_pcam_generators('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4500/4500 [==============================] - 127s 28ms/step - loss: 0.6927 - accuracy: 0.5109 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.69319, saving model to modelRS_weights.hdf5\n",
      "Epoch 2/3\n",
      "4500/4500 [==============================] - 120s 27ms/step - loss: 0.6935 - accuracy: 0.5008 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.69319 to 0.69314, saving model to modelRS_weights.hdf5\n",
      "Epoch 3/3\n",
      "4500/4500 [==============================] - 118s 26ms/step - loss: 0.6936 - accuracy: 0.5005 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.69314\n"
     ]
    }
   ],
   "source": [
    "## Get the model\n",
    "modelRS = get_model('relu','SGD')\n",
    "\n",
    "# Train the model\n",
    "train_model(modelRS, train_genRS, val_genRS, 'modelRS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 TanH activation, SGD optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_genTS, val_genTS = get_pcam_generators('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4500/4500 [==============================] - 120s 26ms/step - loss: 0.5226 - accuracy: 0.7331 - val_loss: 0.4093 - val_accuracy: 0.8194\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.40925, saving model to modelTS_weights.hdf5\n",
      "Epoch 2/3\n",
      "4500/4500 [==============================] - 119s 26ms/step - loss: 0.4026 - accuracy: 0.8201 - val_loss: 0.3563 - val_accuracy: 0.8468\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.40925 to 0.35635, saving model to modelTS_weights.hdf5\n",
      "Epoch 3/3\n",
      "4500/4500 [==============================] - 120s 27ms/step - loss: 0.3424 - accuracy: 0.8515 - val_loss: 0.3268 - val_accuracy: 0.8589\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.35635 to 0.32678, saving model to modelTS_weights.hdf5\n"
     ]
    }
   ],
   "source": [
    "# Get the model\n",
    "modelTS = get_model('tanh','SGD')\n",
    "\n",
    "# Train the model\n",
    "train_model(modelTS, train_genTS, val_genTS, 'modelTS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 LeakyReLU activation, Adam optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_genLA, val_genLA = get_pcam_generators('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4500/4500 [==============================] - 120s 27ms/step - loss: 0.6088 - accuracy: 0.6096 - val_loss: 0.2980 - val_accuracy: 0.8769\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.29802, saving model to modelLA_weights.hdf5\n",
      "Epoch 2/3\n",
      "4500/4500 [==============================] - 118s 26ms/step - loss: 0.3050 - accuracy: 0.8708 - val_loss: 0.2549 - val_accuracy: 0.8993\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.29802 to 0.25491, saving model to modelLA_weights.hdf5\n",
      "Epoch 3/3\n",
      "4500/4500 [==============================] - 118s 26ms/step - loss: 0.2511 - accuracy: 0.8990 - val_loss: 0.2141 - val_accuracy: 0.9137\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.25491 to 0.21410, saving model to modelLA_weights.hdf5\n"
     ]
    }
   ],
   "source": [
    "# Get the model\n",
    "modelLA = get_model('leakyrelu', 'Adam')\n",
    "\n",
    "# Train the model\n",
    "train_model(modelLA, train_genLA, val_genLA, 'modelLA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 ReLU activation, Adam optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_genRA, val_genRA = get_pcam_generators('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4500/4500 [==============================] - 120s 27ms/step - loss: 0.6933 - accuracy: 0.5036 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.69315, saving model to modelRA_weights.hdf5\n",
      "Epoch 2/3\n",
      "4500/4500 [==============================] - 119s 26ms/step - loss: 0.6932 - accuracy: 0.4998 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.69315\n",
      "Epoch 3/3\n",
      "4500/4500 [==============================] - 119s 26ms/step - loss: 0.6932 - accuracy: 0.4995 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.69315\n"
     ]
    }
   ],
   "source": [
    "# Get the model\n",
    "modelRA = get_model('relu', 'Adam')\n",
    "\n",
    "# Train the model\n",
    "train_model(modelRA, train_genRA, val_genRA, 'modelRA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 TanH activation, Adam optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_genTA, val_genTA = get_pcam_generators('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4500/4500 [==============================] - 121s 27ms/step - loss: 0.6996 - accuracy: 0.5061 - val_loss: 0.6940 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.69398, saving model to modelTA_weights.hdf5\n",
      "Epoch 2/3\n",
      "4500/4500 [==============================] - 119s 26ms/step - loss: 0.6980 - accuracy: 0.5000 - val_loss: 0.7182 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.69398\n",
      "Epoch 3/3\n",
      "4500/4500 [==============================] - 119s 26ms/step - loss: 0.6982 - accuracy: 0.4979 - val_loss: 0.6957 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.69398\n"
     ]
    }
   ],
   "source": [
    "# Get the model\n",
    "modelTA = get_model('tanh', 'Adam')\n",
    "\n",
    "# Train the model\n",
    "train_model(modelTA, train_genTA, val_genTA, 'modelTA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 LeakyReLU activation, Nadam optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_genLN, val_genLN = get_pcam_generators('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4500/4500 [==============================] - 119s 26ms/step - loss: 1.1752 - accuracy: 0.5850 - val_loss: 0.4457 - val_accuracy: 0.7931\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.44573, saving model to modelLN_weights.hdf5\n",
      "Epoch 2/3\n",
      "4500/4500 [==============================] - 115s 26ms/step - loss: 0.4439 - accuracy: 0.7963 - val_loss: 0.4126 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.44573 to 0.41262, saving model to modelLN_weights.hdf5\n",
      "Epoch 3/3\n",
      "4500/4500 [==============================] - 116s 26ms/step - loss: 0.3723 - accuracy: 0.8366 - val_loss: 0.3214 - val_accuracy: 0.8674\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.41262 to 0.32140, saving model to modelLN_weights.hdf5\n"
     ]
    }
   ],
   "source": [
    "# Get the model\n",
    "modelLN = get_model('leakyrelu', 'Nadam')\n",
    "\n",
    "# Train the model\n",
    "train_model(modelLN, train_genLN, val_genLN, 'modelLN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 ReLU activation, Nadam optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_genRN, val_genRN = get_pcam_generators('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4500/4500 [==============================] - 118s 26ms/step - loss: 0.6950 - accuracy: 0.4984 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.69316, saving model to modelRN_weights.hdf5\n",
      "Epoch 2/3\n",
      "4500/4500 [==============================] - 115s 26ms/step - loss: 0.6932 - accuracy: 0.5005 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.69316\n",
      "Epoch 3/3\n",
      "4500/4500 [==============================] - 116s 26ms/step - loss: 0.6932 - accuracy: 0.5008 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.69316 to 0.69315, saving model to modelRN_weights.hdf5\n"
     ]
    }
   ],
   "source": [
    "# Get the model\n",
    "modelRN = get_model('relu', 'Nadam')\n",
    "\n",
    "# Train the model\n",
    "train_model(modelRN, train_genRN, val_genRN, 'modelRN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.9 TanH activation, Nadam optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_genTN, val_genTN = get_pcam_generators('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/8p361-lecturer/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4500/4500 [==============================] - 130s 28ms/step - loss: 0.6996 - accuracy: 0.5118 - val_loss: 0.6982 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.69821, saving model to modelTN_weights.hdf5\n",
      "Epoch 2/3\n",
      "4500/4500 [==============================] - 116s 26ms/step - loss: 0.6957 - accuracy: 0.5005 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.69821 to 0.69318, saving model to modelTN_weights.hdf5\n",
      "Epoch 3/3\n",
      "4500/4500 [==============================] - 116s 26ms/step - loss: 0.6961 - accuracy: 0.4972 - val_loss: 0.6970 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.69318\n"
     ]
    }
   ],
   "source": [
    "# Get the model\n",
    "modelTN = get_model('tanh', 'Nadam')\n",
    "\n",
    "# Train the model\n",
    "train_model(modelTN, train_genTN, val_genTN, 'modelTN')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
