{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization of the Layers, Blocks, and Dense Filters\n",
    "Course: 8P361  &emsp;&emsp;  Group: 10\n",
    "\n",
    "Helgers, V.M.J. \t&emsp;&emsp; 1329332 <br>\n",
    "Jong, de R.L.P.D.\t&emsp;  1328328 <br>\n",
    "Korsten, T.\t\t    &emsp;&emsp;&emsp;&emsp; 1340522 <br>\n",
    "Moharir, S. \t\t&emsp;&emsp;&emsp;&emsp; 1296256 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important notes\n",
    "\n",
    "1. Note that all functions needed to execute this notebook can be found in the Optimization_Layers.py file.\n",
    "\n",
    "2. If one wants to run this notebook it is important to add the right path to the image data within the function 'get_pcam_generators' which is called below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. First, import the relevant functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Optimization_Layers import get_pcam_generators, get_model, train_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Get and train the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, there will be an optimization for the layers in the model. There will be optimized with the number of blocks consisting of convolutional layers and a max pooling layer, which will varie between 2 and 3 blocks since there is no possibility of more max pooling layers with the input format and pool_size used. Furthermore there will be optimized with the number of convolutional layers per block, consisting with convolutional layers and a max pooling layer. This number is for now set to vary between 1 and 3. Too many layers may lead to overfitting of the model, so therefore this choice has been made. Furthermore for every combination of the blocks and convolutional layers, 3 models are created with a different first dense layer, e.g. Dense(x, activation ='relu'), with x from [64,128,264]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before every model is run, the dataset is loaded in. This is done again inbefore running a new model, for the sake of keeping the circumstances the same for every model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Model with 2 blocks, containing 1 convolutional layer per block, densenumber equal to 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen2164, val_gen2164 = get_pcam_generators('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/8p361-lecturer/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4500/4500 [==============================] - 123s 27ms/step - loss: 0.5280 - accuracy: 0.7312 - val_loss: 0.4413 - val_accuracy: 0.8126\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.44126, saving model to model2164_weights.hdf5\n",
      "Epoch 2/3\n",
      "4500/4500 [==============================] - 120s 27ms/step - loss: 0.4127 - accuracy: 0.8142 - val_loss: 0.3608 - val_accuracy: 0.8410\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.44126 to 0.36077, saving model to model2164_weights.hdf5\n",
      "Epoch 3/3\n",
      "4500/4500 [==============================] - 120s 27ms/step - loss: 0.3640 - accuracy: 0.8409 - val_loss: 0.3558 - val_accuracy: 0.8442\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.36077 to 0.35585, saving model to model2164_weights.hdf5\n"
     ]
    }
   ],
   "source": [
    "# Get the model\n",
    "model2164 = get_model(2,1,64)\n",
    "\n",
    "# Train the model\n",
    "train_model(model2164, train_gen2164, val_gen2164, 'model2164')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Model with 2 blocks, containing 1 convolutional layer per block, densenumber equal to 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen21128, val_gen21128 = get_pcam_generators('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4500/4500 [==============================] - 120s 27ms/step - loss: 0.5257 - accuracy: 0.7342 - val_loss: 0.4507 - val_accuracy: 0.7908\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.45074, saving model to model21128_weights.hdf5\n",
      "Epoch 2/3\n",
      "4500/4500 [==============================] - 120s 27ms/step - loss: 0.4086 - accuracy: 0.8160 - val_loss: 0.3751 - val_accuracy: 0.8338\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.45074 to 0.37515, saving model to model21128_weights.hdf5\n",
      "Epoch 3/3\n",
      "4500/4500 [==============================] - 121s 27ms/step - loss: 0.3687 - accuracy: 0.8379 - val_loss: 0.3429 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.37515 to 0.34285, saving model to model21128_weights.hdf5\n"
     ]
    }
   ],
   "source": [
    "# Get the model\n",
    "model21128 = get_model(2,1,128)\n",
    "\n",
    "# Train the model\n",
    "train_model(model21128, train_gen21128, val_gen21128, 'model21128')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Model with 2 blocks, containing 1 convolutional layer per block, densenumber equal to 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen21256, val_gen21256 = get_pcam_generators('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4500/4500 [==============================] - 122s 27ms/step - loss: 0.5266 - accuracy: 0.7319 - val_loss: 0.4421 - val_accuracy: 0.7984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.44210, saving model to model21256_weights.hdf5\n",
      "Epoch 2/3\n",
      "4500/4500 [==============================] - 120s 27ms/step - loss: 0.4097 - accuracy: 0.8152 - val_loss: 0.3373 - val_accuracy: 0.8552\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.44210 to 0.33727, saving model to model21256_weights.hdf5\n",
      "Epoch 3/3\n",
      "4500/4500 [==============================] - 120s 27ms/step - loss: 0.3474 - accuracy: 0.8487 - val_loss: 0.3243 - val_accuracy: 0.8652\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.33727 to 0.32434, saving model to model21256_weights.hdf5\n"
     ]
    }
   ],
   "source": [
    "# Get the model\n",
    "model21256 = get_model(2,1,256)\n",
    "\n",
    "# Train the model\n",
    "train_model(model21256, train_gen21256, val_gen21256, 'model21256')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Model with 3 blocks, containing 1 convolutional layer per block, densenumber equal to 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen3164, val_gen3164 = get_pcam_generators('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4500/4500 [==============================] - 121s 27ms/step - loss: 0.5514 - accuracy: 0.7091 - val_loss: 0.4397 - val_accuracy: 0.7962\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.43971, saving model to model3164_weights.hdf5\n",
      "Epoch 2/3\n",
      "4500/4500 [==============================] - 120s 27ms/step - loss: 0.4060 - accuracy: 0.8187 - val_loss: 0.4078 - val_accuracy: 0.8177\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.43971 to 0.40776, saving model to model3164_weights.hdf5\n",
      "Epoch 3/3\n",
      "4500/4500 [==============================] - 120s 27ms/step - loss: 0.3707 - accuracy: 0.8374 - val_loss: 0.3614 - val_accuracy: 0.8381\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.40776 to 0.36135, saving model to model3164_weights.hdf5\n"
     ]
    }
   ],
   "source": [
    "# Get the model\n",
    "model3164 = get_model(3,1,64)\n",
    "\n",
    "# Train the model\n",
    "train_model(model3164, train_gen3164, val_gen3164, 'model3164')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 Model with 3 blocks, containing 1 convolutional layer per block, densenumber equal to 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen31128, val_gen31128 = get_pcam_generators('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4500/4500 [==============================] - 125s 28ms/step - loss: 0.5307 - accuracy: 0.7297 - val_loss: 0.4166 - val_accuracy: 0.8109\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.41664, saving model to model31128_weights.hdf5\n",
      "Epoch 2/3\n",
      "4500/4500 [==============================] - 120s 27ms/step - loss: 0.3949 - accuracy: 0.8241 - val_loss: 0.3327 - val_accuracy: 0.8547\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.41664 to 0.33270, saving model to model31128_weights.hdf5\n",
      "Epoch 3/3\n",
      "4500/4500 [==============================] - 120s 27ms/step - loss: 0.3374 - accuracy: 0.8544 - val_loss: 0.3119 - val_accuracy: 0.8649\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.33270 to 0.31190, saving model to model31128_weights.hdf5\n"
     ]
    }
   ],
   "source": [
    "# Get the model\n",
    "model31128 = get_model(3,1,128)\n",
    "\n",
    "# Train the model\n",
    "train_model(model31128, train_gen31128, val_gen31128, 'model31128')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6 Model with 3 blocks, containing 1 convolutional layer per block, densenumber equal to 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen31256, val_gen31256 = get_pcam_generators('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4500/4500 [==============================] - 120s 27ms/step - loss: 0.5289 - accuracy: 0.7295 - val_loss: 0.4419 - val_accuracy: 0.7989\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.44188, saving model to model31256_weights.hdf5\n",
      "Epoch 2/3\n",
      "4500/4500 [==============================] - 119s 27ms/step - loss: 0.4047 - accuracy: 0.8180 - val_loss: 0.3669 - val_accuracy: 0.8426\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.44188 to 0.36692, saving model to model31256_weights.hdf5\n",
      "Epoch 3/3\n",
      "4500/4500 [==============================] - 120s 27ms/step - loss: 0.3468 - accuracy: 0.8494 - val_loss: 0.3428 - val_accuracy: 0.8518\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.36692 to 0.34277, saving model to model31256_weights.hdf5\n"
     ]
    }
   ],
   "source": [
    "# Get the model\n",
    "model31256 = get_model(3,1,256)\n",
    "\n",
    "# Train the model\n",
    "train_model(model31256, train_gen31256, val_gen31256, 'model31256')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.7 Model with 2 blocks, containing 2 convolutional layer per block, densenumber equal to 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen2264, val_gen2264 = get_pcam_generators('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4500/4500 [==============================] - 121s 27ms/step - loss: 0.5876 - accuracy: 0.6658 - val_loss: 0.3649 - val_accuracy: 0.8407\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.36490, saving model to model2264_weights.hdf5\n",
      "Epoch 2/3\n",
      "4500/4500 [==============================] - 120s 27ms/step - loss: 0.3958 - accuracy: 0.8236 - val_loss: 0.3683 - val_accuracy: 0.8331\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.36490\n",
      "Epoch 3/3\n",
      "4500/4500 [==============================] - 120s 27ms/step - loss: 0.3466 - accuracy: 0.8487 - val_loss: 0.3451 - val_accuracy: 0.8475\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.36490 to 0.34510, saving model to model2264_weights.hdf5\n"
     ]
    }
   ],
   "source": [
    "# Get the model\n",
    "model2264 = get_model(2,2,64)\n",
    "\n",
    "# Train the model\n",
    "train_model(model2264, train_gen2264, val_gen2264, 'model2264')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.8 Model with 2 blocks, containing 2 convolutional layer per block, densenumber equal to 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen22128, val_gen22128 = get_pcam_generators('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4500/4500 [==============================] - 121s 27ms/step - loss: 0.5720 - accuracy: 0.6793 - val_loss: 0.3718 - val_accuracy: 0.8363\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.37181, saving model to model22128_weights.hdf5\n",
      "Epoch 2/3\n",
      "4500/4500 [==============================] - 120s 27ms/step - loss: 0.3792 - accuracy: 0.8329 - val_loss: 0.3388 - val_accuracy: 0.8572\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.37181 to 0.33876, saving model to model22128_weights.hdf5\n",
      "Epoch 3/3\n",
      "4500/4500 [==============================] - 120s 27ms/step - loss: 0.3258 - accuracy: 0.8616 - val_loss: 0.3066 - val_accuracy: 0.8694\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.33876 to 0.30664, saving model to model22128_weights.hdf5\n"
     ]
    }
   ],
   "source": [
    "# Get the model\n",
    "model22128 = get_model(2,2,128)\n",
    "\n",
    "# Train the model\n",
    "train_model(model22128, train_gen22128, val_gen22128, 'model22128')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.9 Model with 2 blocks, containing 2 convolutional layer per block, densenumber equal to 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen22256, val_gen22256 = get_pcam_generators('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4500/4500 [==============================] - 122s 27ms/step - loss: 0.6023 - accuracy: 0.6529 - val_loss: 0.4255 - val_accuracy: 0.8018\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.42551, saving model to model22256_weights.hdf5\n",
      "Epoch 2/3\n",
      "4500/4500 [==============================] - 121s 27ms/step - loss: 0.4213 - accuracy: 0.8076 - val_loss: 0.4119 - val_accuracy: 0.8122\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.42551 to 0.41188, saving model to model22256_weights.hdf5\n",
      "Epoch 3/3\n",
      "4500/4500 [==============================] - 120s 27ms/step - loss: 0.3549 - accuracy: 0.8440 - val_loss: 0.3117 - val_accuracy: 0.8659\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.41188 to 0.31170, saving model to model22256_weights.hdf5\n"
     ]
    }
   ],
   "source": [
    "# Get the model\n",
    "model22256 = get_model(2,2,256)\n",
    "\n",
    "# Train the model\n",
    "train_model(model22256, train_gen22256, val_gen22256, 'model22256')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.10 Model with 3 blocks, containing 2 convolutional layer per block, densenumber equal to 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen3264, val_gen3264 = get_pcam_generators('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4500/4500 [==============================] - 122s 27ms/step - loss: 0.5655 - accuracy: 0.6922 - val_loss: 0.4350 - val_accuracy: 0.8036\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.43501, saving model to model3264_weights.hdf5\n",
      "Epoch 2/3\n",
      "4500/4500 [==============================] - 121s 27ms/step - loss: 0.4304 - accuracy: 0.8040 - val_loss: 0.3740 - val_accuracy: 0.8353\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.43501 to 0.37403, saving model to model3264_weights.hdf5\n",
      "Epoch 3/3\n",
      "4500/4500 [==============================] - 120s 27ms/step - loss: 0.3677 - accuracy: 0.8368 - val_loss: 0.3508 - val_accuracy: 0.8386\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.37403 to 0.35079, saving model to model3264_weights.hdf5\n"
     ]
    }
   ],
   "source": [
    "# Get the model\n",
    "model3264 = get_model(3,2,64)\n",
    "\n",
    "# Train the model\n",
    "train_model(model3264, train_gen3264, val_gen3264, 'model3264')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.11 Model with 3 blocks, containing 2 convolutional layer per block, densenumber equal to 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen32128, val_gen32128 = get_pcam_generators('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4500/4500 [==============================] - 122s 27ms/step - loss: 0.6430 - accuracy: 0.5969 - val_loss: 0.3922 - val_accuracy: 0.8249\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.39219, saving model to model32128_weights.hdf5\n",
      "Epoch 2/3\n",
      "4500/4500 [==============================] - 121s 27ms/step - loss: 0.3960 - accuracy: 0.8248 - val_loss: 0.3596 - val_accuracy: 0.8412\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.39219 to 0.35962, saving model to model32128_weights.hdf5\n",
      "Epoch 3/3\n",
      "4500/4500 [==============================] - 121s 27ms/step - loss: 0.3302 - accuracy: 0.8584 - val_loss: 0.2789 - val_accuracy: 0.8823\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.35962 to 0.27893, saving model to model32128_weights.hdf5\n"
     ]
    }
   ],
   "source": [
    "# Get the model\n",
    "model32128 = get_model(3,2,128)\n",
    "\n",
    "# Train the model\n",
    "train_model(model32128, train_gen32128, val_gen32128, 'model32128')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.12 Model with 3 blocks, containing 2 convolutional layer per block, densenumber equal to 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen32256, val_gen32256 = get_pcam_generators('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4500/4500 [==============================] - 121s 27ms/step - loss: 0.5831 - accuracy: 0.6737 - val_loss: 0.4093 - val_accuracy: 0.8163\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.40932, saving model to model32256_weights.hdf5\n",
      "Epoch 2/3\n",
      "4500/4500 [==============================] - 121s 27ms/step - loss: 0.3860 - accuracy: 0.8288 - val_loss: 0.3028 - val_accuracy: 0.8721\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.40932 to 0.30277, saving model to model32256_weights.hdf5\n",
      "Epoch 3/3\n",
      "4500/4500 [==============================] - 122s 27ms/step - loss: 0.3038 - accuracy: 0.8720 - val_loss: 0.2788 - val_accuracy: 0.8806\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.30277 to 0.27876, saving model to model32256_weights.hdf5\n"
     ]
    }
   ],
   "source": [
    "# Get the model\n",
    "model32256 = get_model(3,2,256)\n",
    "\n",
    "# Train the model\n",
    "train_model(model32256, train_gen32256, val_gen32256, 'model32256')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.13 Model with 2 blocks, containing 3 convolutional layers per block, densenumber equal to 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen2364, val_gen2364 = get_pcam_generators('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4500/4500 [==============================] - 131s 29ms/step - loss: 0.6686 - accuracy: 0.5654 - val_loss: 0.4669 - val_accuracy: 0.7804\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.46692, saving model to model2364_weights.hdf5\n",
      "Epoch 2/3\n",
      "4500/4500 [==============================] - 131s 29ms/step - loss: 0.4540 - accuracy: 0.7910 - val_loss: 0.4112 - val_accuracy: 0.8163\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.46692 to 0.41116, saving model to model2364_weights.hdf5\n",
      "Epoch 3/3\n",
      "4500/4500 [==============================] - 135s 30ms/step - loss: 0.4007 - accuracy: 0.8192 - val_loss: 0.3766 - val_accuracy: 0.8346\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.41116 to 0.37662, saving model to model2364_weights.hdf5\n"
     ]
    }
   ],
   "source": [
    "# Get the model\n",
    "model2364 = get_model(2,3,64)\n",
    "\n",
    "# Train the model\n",
    "train_model(model2364, train_gen2364, val_gen2364, 'model2364')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.14 Model with 2 blocks, containing 3 convolutional layers per block, densenumber equal to 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen23128, val_gen23128 = get_pcam_generators('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4500/4500 [==============================] - 135s 30ms/step - loss: 0.6918 - accuracy: 0.5153 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.69306, saving model to model23128_weights.hdf5\n",
      "Epoch 2/3\n",
      "4500/4500 [==============================] - 133s 30ms/step - loss: 0.6604 - accuracy: 0.5631 - val_loss: 0.3976 - val_accuracy: 0.8289\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.69306 to 0.39762, saving model to model23128_weights.hdf5\n",
      "Epoch 3/3\n",
      "4500/4500 [==============================] - 131s 29ms/step - loss: 0.4119 - accuracy: 0.8156 - val_loss: 0.3653 - val_accuracy: 0.8443\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.39762 to 0.36531, saving model to model23128_weights.hdf5\n"
     ]
    }
   ],
   "source": [
    "# Get the model\n",
    "model23128 = get_model(2,3,128)\n",
    "\n",
    "# Train the model\n",
    "train_model(model23128, train_gen23128, val_gen23128, 'model23128')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.15 Model with 2 blocks, containing 3 convolutional layers per block, densenumber equal to 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen23256, val_gen23256 = get_pcam_generators('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4500/4500 [==============================] - 120s 27ms/step - loss: 0.6888 - accuracy: 0.5212 - val_loss: 0.4520 - val_accuracy: 0.7892\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.45197, saving model to model23256_weights.hdf5\n",
      "Epoch 2/3\n",
      "4500/4500 [==============================] - 120s 27ms/step - loss: 0.4677 - accuracy: 0.7835 - val_loss: 0.4443 - val_accuracy: 0.7970\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.45197 to 0.44428, saving model to model23256_weights.hdf5\n",
      "Epoch 3/3\n",
      "4500/4500 [==============================] - 120s 27ms/step - loss: 0.4113 - accuracy: 0.8143 - val_loss: 0.3700 - val_accuracy: 0.8324\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.44428 to 0.37000, saving model to model23256_weights.hdf5\n"
     ]
    }
   ],
   "source": [
    "# Get the model\n",
    "model23256 = get_model(2,3,256)\n",
    "\n",
    "# Train the model\n",
    "train_model(model23256, train_gen23256, val_gen23256, 'model23256')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.16 Model with 3 blocks, containing 3 convolutional layers per block, densenumber equal to 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen3364, val_gen3364 = get_pcam_generators('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4500/4500 [==============================] - 152s 34ms/step - loss: 0.6907 - accuracy: 0.5111 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.69317, saving model to model3364_weights.hdf5\n",
      "Epoch 2/3\n",
      "4500/4500 [==============================] - 152s 34ms/step - loss: 0.6739 - accuracy: 0.5413 - val_loss: 0.4515 - val_accuracy: 0.7921\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.69317 to 0.45154, saving model to model3364_weights.hdf5\n",
      "Epoch 3/3\n",
      "4500/4500 [==============================] - 151s 34ms/step - loss: 0.4340 - accuracy: 0.8020 - val_loss: 0.3569 - val_accuracy: 0.8443\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.45154 to 0.35694, saving model to model3364_weights.hdf5\n"
     ]
    }
   ],
   "source": [
    "# Get the model\n",
    "model3364 = get_model(3,3,64)\n",
    "\n",
    "# Train the model\n",
    "train_model(model3364, train_gen3364, val_gen3364, 'model3364')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.17 Model with 3 blocks, containing 3 convolutional layers per block, densenumber equal to 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen33128, val_gen33128 = get_pcam_generators('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4500/4500 [==============================] - 138s 31ms/step - loss: 0.6925 - accuracy: 0.5132 - val_loss: 0.6914 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.69142, saving model to model33128_weights.hdf5\n",
      "Epoch 2/3\n",
      "4500/4500 [==============================] - 137s 30ms/step - loss: 0.6406 - accuracy: 0.6015 - val_loss: 0.4253 - val_accuracy: 0.8062\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.69142 to 0.42532, saving model to model33128_weights.hdf5\n",
      "Epoch 3/3\n",
      "4500/4500 [==============================] - 136s 30ms/step - loss: 0.4360 - accuracy: 0.8018 - val_loss: 0.3784 - val_accuracy: 0.8334\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.42532 to 0.37838, saving model to model33128_weights.hdf5\n"
     ]
    }
   ],
   "source": [
    "# Get the model\n",
    "model33128 = get_model(3,3,128)\n",
    "\n",
    "# Train the model\n",
    "train_model(model33128, train_gen33128, val_gen33128, 'model33128')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.18 Model with 3 blocks, containing 3 convolutional layers per block, densenumber equal to 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen33256, val_gen33256 = get_pcam_generators('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/8p361-lecturer/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4500/4500 [==============================] - 130s 28ms/step - loss: 0.5922 - accuracy: 0.6548 - val_loss: 0.3485 - val_accuracy: 0.8462\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.34850, saving model to model33256_weights.hdf5\n",
      "Epoch 2/3\n",
      "4500/4500 [==============================] - 124s 28ms/step - loss: 0.3687 - accuracy: 0.8384 - val_loss: 0.2923 - val_accuracy: 0.8759\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.34850 to 0.29235, saving model to model33256_weights.hdf5\n",
      "Epoch 3/3\n",
      "4500/4500 [==============================] - 124s 27ms/step - loss: 0.3022 - accuracy: 0.8739 - val_loss: 0.2821 - val_accuracy: 0.8857\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.29235 to 0.28215, saving model to model33256_weights.hdf5\n"
     ]
    }
   ],
   "source": [
    "# Get the model\n",
    "model33256 = get_model(3,3,256)\n",
    "\n",
    "# Train the model\n",
    "train_model(model33256, train_gen33256, val_gen33256, 'model33256')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
