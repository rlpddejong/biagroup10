{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization of the Optimization algorithm and Activation\n",
    "Course: 8P361  &emsp;&emsp;  Group: 10\n",
    "\n",
    "Helgers, V.M.J. \t&emsp;&emsp; 1329332 <br>\n",
    "Jong, de R.L.P.D.\t&emsp;  1328328 <br>\n",
    "Korsten, T.\t\t    &emsp;&emsp;&emsp;&emsp; 1340522 <br>\n",
    "Moharir, S. \t\t&emsp;&emsp;&emsp;&emsp; 1296256 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important notes\n",
    "\n",
    "1. Note that all functions needed to execute this notebook can be found in the Optimization_Batch.py file.\n",
    "\n",
    "2. If one wants to run this notebook it is important to add the right path to the image data within the function 'get_pcam_generators' which is called below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What the notebook does\n",
    "This notebook varies the batchsize. The batchsizes for both the training and validation set are changed in the same way, so they keep the same value during the optimization. The given value was 32 so there has been chosen to both test smaller and bigger batchsizes. Below a list of the batchsizes that are taken into account in this optimization process.\n",
    "\n",
    "Batchsizes to be varied between are 8, 16, 32, 64, and 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. First, import the relevant functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Optimization_Batch import get_pcam_generators, get_model, train_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Get the models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Batchsize of 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen8, val_gen8 = get_pcam_generators('data', train_batch_size=8, val_batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model8 = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/8p361-lecturer/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "18000/18000 [==============================] - 284s 15ms/step - loss: 2.3184 - accuracy: 0.5259 - val_loss: 0.5859 - val_accuracy: 0.6904\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.58594, saving model to model8_weights.hdf5\n",
      "Epoch 2/3\n",
      "18000/18000 [==============================] - 280s 16ms/step - loss: 367.9772 - accuracy: 0.6202 - val_loss: 3.7880 - val_accuracy: 0.4998\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.58594\n",
      "Epoch 3/3\n",
      "18000/18000 [==============================] - 281s 16ms/step - loss: 114.9701 - accuracy: 0.5588 - val_loss: 2.0156 - val_accuracy: 0.4993\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.58594\n"
     ]
    }
   ],
   "source": [
    "train_model(model8,train_gen8,val_gen8,'model8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Batchsize of 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen16, val_gen16 = get_pcam_generators('data', train_batch_size=16, val_batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model16 = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "9000/9000 [==============================] - 193s 21ms/step - loss: 0.6465 - accuracy: 0.6098 - val_loss: 0.4399 - val_accuracy: 0.8027\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.43985, saving model to model16_weights.hdf5\n",
      "Epoch 2/3\n",
      "9000/9000 [==============================] - 194s 22ms/step - loss: 142.3341 - accuracy: 0.7380 - val_loss: 0.5602 - val_accuracy: 0.7294\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.43985\n",
      "Epoch 3/3\n",
      "9000/9000 [==============================] - 195s 22ms/step - loss: 1.3199 - accuracy: 0.6369 - val_loss: 0.7243 - val_accuracy: 0.4940\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.43985\n"
     ]
    }
   ],
   "source": [
    "train_model(model16,train_gen16,val_gen16,'model16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Batchsize of 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen32, val_gen32 = get_pcam_generators('data', train_batch_size=32, val_batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model32 = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/8p361-lecturer/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4500/4500 [==============================] - 170s 36ms/step - loss: 0.6070 - accuracy: 0.6224 - val_loss: 0.3521 - val_accuracy: 0.8474\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.35214, saving model to model32_weights.hdf5\n",
      "Epoch 2/3\n",
      "4500/4500 [==============================] - 161s 36ms/step - loss: 0.3460 - accuracy: 0.8505 - val_loss: 0.2916 - val_accuracy: 0.8731\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.35214 to 0.29161, saving model to model32_weights.hdf5\n",
      "Epoch 3/3\n",
      "4500/4500 [==============================] - 160s 36ms/step - loss: 0.2762 - accuracy: 0.8857 - val_loss: 0.2450 - val_accuracy: 0.9019\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.29161 to 0.24504, saving model to model32_weights.hdf5\n"
     ]
    }
   ],
   "source": [
    "train_model(model32,train_gen32,val_gen32,'model32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Batchsize of 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen64, val_gen64 = get_pcam_generators('data', train_batch_size=64, val_batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model64 = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2250/2250 [==============================] - 155s 68ms/step - loss: 0.5637 - accuracy: 0.6742 - val_loss: 0.3385 - val_accuracy: 0.8538\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.33854, saving model to model64_weights.hdf5\n",
      "Epoch 2/3\n",
      "2250/2250 [==============================] - 151s 67ms/step - loss: 0.3312 - accuracy: 0.8572 - val_loss: 0.2711 - val_accuracy: 0.8860\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.33854 to 0.27110, saving model to model64_weights.hdf5\n",
      "Epoch 3/3\n",
      "2250/2250 [==============================] - 150s 67ms/step - loss: 0.2441 - accuracy: 0.9025 - val_loss: 0.2116 - val_accuracy: 0.9172\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.27110 to 0.21160, saving model to model64_weights.hdf5\n"
     ]
    }
   ],
   "source": [
    "train_model(model64,train_gen64,val_gen64,'model64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 Batchsize of 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen128, val_gen128 = get_pcam_generators('data', train_batch_size=128, val_batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model128 = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1125/1125 [==============================] - 153s 133ms/step - loss: 0.4808 - accuracy: 0.7620 - val_loss: 0.3850 - val_accuracy: 0.8314\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.38498, saving model to model128_weights.hdf5\n",
      "Epoch 2/3\n",
      "1125/1125 [==============================] - 150s 133ms/step - loss: 0.3011 - accuracy: 0.8740 - val_loss: 0.3001 - val_accuracy: 0.8602\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.38498 to 0.30014, saving model to model128_weights.hdf5\n",
      "Epoch 3/3\n",
      "1125/1125 [==============================] - 149s 132ms/step - loss: 0.2485 - accuracy: 0.8986 - val_loss: 0.2374 - val_accuracy: 0.9054\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.30014 to 0.23735, saving model to model128_weights.hdf5\n"
     ]
    }
   ],
   "source": [
    "train_model(model128,train_gen128,val_gen128,'model128')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
